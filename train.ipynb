{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "birds_audio_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HsengivS/Birds-Audio-Classification/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmZB03g8TpAy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bbca68e-9b54-4b7f-dfb6-8050c211ed6f"
      },
      "source": [
        "import glob\n",
        "\n",
        "# Importing drive method from colab for accessing google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pMGaHCcUQsV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "196e1270-b6eb-40d8-dada-5ade810a7263"
      },
      "source": [
        "!ls \"/content/drive/My Drive/BIRDS_AUDIO_CLASSIFIER\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AmericanCrow  BlueJay  EasternWoodPewee  NorthernWaterthrush  Ovenbird\tVeery\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsKIdLw5TPPL"
      },
      "source": [
        "# Pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Scikit learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "# Keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Audio\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "# Plot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Utility\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import itertools"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtEKhdlTUf_9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5414898-616e-442c-b9bc-fa17f16da4e4"
      },
      "source": [
        "data_folders = [\"/content/drive/My Drive/BIRDS_AUDIO_CLASSIFIER/\"+i for i in os.listdir(\"/content/drive/My Drive/BIRDS_AUDIO_CLASSIFIER\")]\n",
        "data_folders"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/BIRDS_AUDIO_CLASSIFIER/AmericanCrow',\n",
              " '/content/drive/My Drive/BIRDS_AUDIO_CLASSIFIER/NorthernWaterthrush',\n",
              " '/content/drive/My Drive/BIRDS_AUDIO_CLASSIFIER/Ovenbird',\n",
              " '/content/drive/My Drive/BIRDS_AUDIO_CLASSIFIER/Veery',\n",
              " '/content/drive/My Drive/BIRDS_AUDIO_CLASSIFIER/BlueJay',\n",
              " '/content/drive/My Drive/BIRDS_AUDIO_CLASSIFIER/EasternWoodPewee']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfPwwccQTUJT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "721932de-c7ed-41db-fa1b-ab8496f10ca3"
      },
      "source": [
        "%%time\n",
        "dataset = []\n",
        "for folder in data_folders:\n",
        "  label = folder.split(\"/\")[-1]\n",
        "  for filename in os.listdir(folder):\n",
        "    fn = os.path.join(folder, filename)\n",
        "    if librosa.get_duration(filename=fn)>=4:\n",
        "      dataset.append({\"filename\":fn, \"label\":label})"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 10.4 s, sys: 27.2 s, total: 37.6 s\n",
            "Wall time: 11min 9s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PT4WZe0dvbVQ"
      },
      "source": [
        "dataset = pd.DataFrame(dataset)\n",
        "dataset = shuffle(dataset, random_state=42)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EGBommJzW7B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13246e1d-2c1d-4545-a186-7e7dae3ffb21"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1581 entries, 1385 to 1159\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   filename  1581 non-null   object\n",
            " 1   label     1581 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 37.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLQe2qqMzZo5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae7df44a-9052-4f86-bd8c-d8ee58ac62cf"
      },
      "source": [
        "dataset.label.value_counts()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BlueJay                370\n",
              "AmericanCrow           280\n",
              "NorthernWaterthrush    275\n",
              "Ovenbird               229\n",
              "Veery                  216\n",
              "EasternWoodPewee       211\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsMHheqHzg0m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "6444a311-c107-4e7d-e35d-78dc4df8bbb8"
      },
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "dataset.label.value_counts().plot(kind='bar', title=\"Dataset distribution\")\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRoHQQxYzl9C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "279ccfac-efd7-4075-a379-5bdef902ee2a"
      },
      "source": [
        "train, test = train_test_split(dataset, test_size=0.05, random_state=42)\n",
        "\n",
        "print(\"Train: %i\" % len(train))\n",
        "print(\"Test: %i\" % len(test))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: 1501\n",
            "Test: 80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpz2NEu80Cdy"
      },
      "source": [
        "Extract Audio Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8gYqwOXzzc6"
      },
      "source": [
        "def extract_features(audio_path):\n",
        "    y, sr = librosa.load(audio_path, duration=4)\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
        "    return mfccs"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hysktw1V0GPW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05e26e60-50fa-4ede-aba0-43efb0ea04ad"
      },
      "source": [
        "extract_features(dataset.iloc[0,0]).shape"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 173)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eK6xvAWE0JV9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8949bc15-2881-4526-d202-f1315cebfe84"
      },
      "source": [
        "%%time\n",
        "x_train, x_test = [], []\n",
        "print(\"Extract features from TRAIN  and TEST dataset\")\n",
        "for idx in tqdm(range(len(train))):\n",
        "    x_train.append(extract_features(train.filename.iloc[idx]))\n",
        "\n",
        "for idx in tqdm(range(len(test))):\n",
        "    x_test.append(extract_features(test.filename.iloc[idx]))\n",
        "    \n",
        "print(\"here------------\")\n",
        "\n",
        "# print(x_train[0:2])\n",
        "\n",
        "x_train = np.asarray(x_train)\n",
        "x_test = np.asarray(x_test)\n",
        "print(22222222222222222222222222222222222222)\n",
        "print(\"X train:\", x_train.shape)\n",
        "print(\"X test:\", x_test.shape)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1501 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extract features from TRAIN  and TEST dataset\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1501/1501 [13:42<00:00,  1.82it/s]\n",
            "100%|██████████| 80/80 [00:42<00:00,  1.88it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "here------------\n",
            "22222222222222222222222222222222222222\n",
            "X train: (1501, 40, 173)\n",
            "X test: (80, 40, 173)\n",
            "CPU times: user 4min 50s, sys: 3min 8s, total: 7min 58s\n",
            "Wall time: 14min 25s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljlxsDn84LcS"
      },
      "source": [
        "Encode Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je7XfnbZ0Nh-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc24b930-dcde-4fcf-c196-3aa4c5e99a7a"
      },
      "source": [
        "%%time\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(train.label)\n",
        "\n",
        "y_train = encoder.transform(train.label)\n",
        "y_test = encoder.transform(test.label)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 929 µs, sys: 1.55 ms, total: 2.48 ms\n",
            "Wall time: 1.25 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j3-BNLr4RET"
      },
      "source": [
        "Compute class weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-wJTmez4QqS"
      },
      "source": [
        "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
        "\n",
        "# class_weights\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SObGKnvY4XuN"
      },
      "source": [
        "Shape the input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDFAY-fU4HqC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "491fc8f2-cb2f-4900-8f49-a8e462643890"
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "\n",
        "\n",
        "print(\"X train:\", x_train.shape)\n",
        "print(\"Y train:\", y_train.shape)\n",
        "print()\n",
        "print(\"X test:\", x_test.shape)\n",
        "print(\"Y test:\", y_test.shape)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X train: (1501, 40, 173, 1)\n",
            "Y train: (1501, 6)\n",
            "\n",
            "X test: (80, 40, 173, 1)\n",
            "Y test: (80, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-H5RhiC48To"
      },
      "source": [
        "Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRtkmGQm4HZq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35db8403-bf70-4451-a0a5-6416f34e82e3"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters=16, kernel_size=2, input_shape=(x_train.shape[1],x_train.shape[2],x_train.shape[3]), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(GlobalAveragePooling2D())\n",
        "\n",
        "model.add(Dense(len(encoder.classes_), activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 39, 172, 16)       80        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 19, 86, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 19, 86, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 18, 85, 32)        2080      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 9, 42, 32)         0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 9, 42, 32)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 8, 41, 64)         8256      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 4, 20, 64)         0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 4, 20, 64)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 3, 19, 128)        32896     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 1, 9, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 1, 9, 128)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 774       \n",
            "=================================================================\n",
            "Total params: 44,086\n",
            "Trainable params: 44,086\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VC4DBeKzzE5"
      },
      "source": [
        "# Compile\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FR_OSkCB5ARU"
      },
      "source": [
        "Fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syk9KkSl5A3s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7fbf6f0-60c2-4e99-afaa-4bdaff83def8"
      },
      "source": [
        "%%time\n",
        "history = model.fit(x_train, y_train,\n",
        "              batch_size=100,\n",
        "              epochs=300,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "\n",
        "# %%time\n",
        "# history = model.fit(x_train, y_train,\n",
        "#               batch_size=128,\n",
        "#               epochs=10,\n",
        "#               validation_data=(x_test, y_test),\n",
        "#               class_weight=class_weights,\n",
        "#               shuffle=True)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 5.2351 - accuracy: 0.1845 - val_loss: 1.9637 - val_accuracy: 0.1875\n",
            "Epoch 2/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 2.2612 - accuracy: 0.1885 - val_loss: 1.7845 - val_accuracy: 0.1625\n",
            "Epoch 3/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 1.8748 - accuracy: 0.2192 - val_loss: 1.7728 - val_accuracy: 0.2500\n",
            "Epoch 4/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.8342 - accuracy: 0.2418 - val_loss: 1.7420 - val_accuracy: 0.2250\n",
            "Epoch 5/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.7596 - accuracy: 0.2712 - val_loss: 1.7123 - val_accuracy: 0.3000\n",
            "Epoch 6/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.7215 - accuracy: 0.2845 - val_loss: 1.7003 - val_accuracy: 0.3625\n",
            "Epoch 7/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 1.6966 - accuracy: 0.3031 - val_loss: 1.6796 - val_accuracy: 0.3000\n",
            "Epoch 8/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.6766 - accuracy: 0.3271 - val_loss: 1.6737 - val_accuracy: 0.3125\n",
            "Epoch 9/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.6550 - accuracy: 0.3118 - val_loss: 1.6207 - val_accuracy: 0.3750\n",
            "Epoch 10/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 1.5506 - accuracy: 0.3704 - val_loss: 1.5494 - val_accuracy: 0.3625\n",
            "Epoch 11/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 1.5204 - accuracy: 0.3837 - val_loss: 1.4823 - val_accuracy: 0.4375\n",
            "Epoch 12/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 1.4740 - accuracy: 0.3991 - val_loss: 1.4118 - val_accuracy: 0.4375\n",
            "Epoch 13/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.5043 - accuracy: 0.3984 - val_loss: 1.4425 - val_accuracy: 0.3750\n",
            "Epoch 14/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.4719 - accuracy: 0.4197 - val_loss: 1.3980 - val_accuracy: 0.4250\n",
            "Epoch 15/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 1.4212 - accuracy: 0.4157 - val_loss: 1.3879 - val_accuracy: 0.5000\n",
            "Epoch 16/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 1.4623 - accuracy: 0.4151 - val_loss: 1.3721 - val_accuracy: 0.4125\n",
            "Epoch 17/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 1.4548 - accuracy: 0.4137 - val_loss: 1.3558 - val_accuracy: 0.4000\n",
            "Epoch 18/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 1.4008 - accuracy: 0.4384 - val_loss: 1.3511 - val_accuracy: 0.4250\n",
            "Epoch 19/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.3623 - accuracy: 0.4570 - val_loss: 1.3088 - val_accuracy: 0.4625\n",
            "Epoch 20/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.3414 - accuracy: 0.4737 - val_loss: 1.2952 - val_accuracy: 0.4625\n",
            "Epoch 21/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.2869 - accuracy: 0.5003 - val_loss: 1.2654 - val_accuracy: 0.4375\n",
            "Epoch 22/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.2894 - accuracy: 0.4870 - val_loss: 1.2419 - val_accuracy: 0.6250\n",
            "Epoch 23/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 1.3379 - accuracy: 0.4544 - val_loss: 1.2513 - val_accuracy: 0.5750\n",
            "Epoch 24/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.2781 - accuracy: 0.4870 - val_loss: 1.2388 - val_accuracy: 0.6000\n",
            "Epoch 25/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.2255 - accuracy: 0.5283 - val_loss: 1.1998 - val_accuracy: 0.6125\n",
            "Epoch 26/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 1.2504 - accuracy: 0.4957 - val_loss: 1.2324 - val_accuracy: 0.5750\n",
            "Epoch 27/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 1.2259 - accuracy: 0.5250 - val_loss: 1.2073 - val_accuracy: 0.5875\n",
            "Epoch 28/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 1.3017 - accuracy: 0.4597 - val_loss: 1.2260 - val_accuracy: 0.5250\n",
            "Epoch 29/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.2030 - accuracy: 0.5130 - val_loss: 1.2167 - val_accuracy: 0.5875\n",
            "Epoch 30/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.1561 - accuracy: 0.5603 - val_loss: 1.1914 - val_accuracy: 0.6250\n",
            "Epoch 31/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 1.1381 - accuracy: 0.5523 - val_loss: 1.1737 - val_accuracy: 0.6000\n",
            "Epoch 32/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 1.3751 - accuracy: 0.4637 - val_loss: 1.3239 - val_accuracy: 0.4750\n",
            "Epoch 33/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 1.2271 - accuracy: 0.5137 - val_loss: 1.2261 - val_accuracy: 0.5500\n",
            "Epoch 34/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.1814 - accuracy: 0.5423 - val_loss: 1.2175 - val_accuracy: 0.5125\n",
            "Epoch 35/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.1629 - accuracy: 0.5476 - val_loss: 1.1931 - val_accuracy: 0.5500\n",
            "Epoch 36/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.1582 - accuracy: 0.5570 - val_loss: 1.1885 - val_accuracy: 0.6250\n",
            "Epoch 37/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.1371 - accuracy: 0.5610 - val_loss: 1.1718 - val_accuracy: 0.6250\n",
            "Epoch 38/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.0936 - accuracy: 0.5809 - val_loss: 1.1721 - val_accuracy: 0.5750\n",
            "Epoch 39/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.1930 - accuracy: 0.5316 - val_loss: 1.1901 - val_accuracy: 0.6250\n",
            "Epoch 40/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.1348 - accuracy: 0.5596 - val_loss: 1.2433 - val_accuracy: 0.5625\n",
            "Epoch 41/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.0891 - accuracy: 0.5869 - val_loss: 1.1575 - val_accuracy: 0.5625\n",
            "Epoch 42/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.0987 - accuracy: 0.5789 - val_loss: 1.1783 - val_accuracy: 0.6125\n",
            "Epoch 43/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.0809 - accuracy: 0.5856 - val_loss: 1.1610 - val_accuracy: 0.5750\n",
            "Epoch 44/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 1.1252 - accuracy: 0.5650 - val_loss: 1.1741 - val_accuracy: 0.5750\n",
            "Epoch 45/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.0978 - accuracy: 0.5710 - val_loss: 1.1810 - val_accuracy: 0.6000\n",
            "Epoch 46/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.0468 - accuracy: 0.6076 - val_loss: 1.1575 - val_accuracy: 0.5875\n",
            "Epoch 47/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.0420 - accuracy: 0.6083 - val_loss: 1.1757 - val_accuracy: 0.5625\n",
            "Epoch 48/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.0847 - accuracy: 0.5883 - val_loss: 1.2038 - val_accuracy: 0.5750\n",
            "Epoch 49/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.0250 - accuracy: 0.6262 - val_loss: 1.1723 - val_accuracy: 0.5250\n",
            "Epoch 50/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.0116 - accuracy: 0.6216 - val_loss: 1.1621 - val_accuracy: 0.5500\n",
            "Epoch 51/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.9576 - accuracy: 0.6482 - val_loss: 1.1466 - val_accuracy: 0.6125\n",
            "Epoch 52/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 1.0491 - accuracy: 0.6156 - val_loss: 1.1522 - val_accuracy: 0.5875\n",
            "Epoch 53/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 1.0052 - accuracy: 0.6236 - val_loss: 1.2272 - val_accuracy: 0.4750\n",
            "Epoch 54/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.0957 - accuracy: 0.5876 - val_loss: 1.1419 - val_accuracy: 0.6000\n",
            "Epoch 55/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.9803 - accuracy: 0.6402 - val_loss: 1.0869 - val_accuracy: 0.6250\n",
            "Epoch 56/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.9825 - accuracy: 0.6369 - val_loss: 1.1120 - val_accuracy: 0.6000\n",
            "Epoch 57/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.9381 - accuracy: 0.6589 - val_loss: 1.0998 - val_accuracy: 0.6000\n",
            "Epoch 58/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.9208 - accuracy: 0.6496 - val_loss: 1.0756 - val_accuracy: 0.6000\n",
            "Epoch 59/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.9023 - accuracy: 0.6736 - val_loss: 1.1100 - val_accuracy: 0.6000\n",
            "Epoch 60/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.9871 - accuracy: 0.6302 - val_loss: 1.1390 - val_accuracy: 0.5875\n",
            "Epoch 61/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.9224 - accuracy: 0.6542 - val_loss: 1.1321 - val_accuracy: 0.6250\n",
            "Epoch 62/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.2000 - accuracy: 0.5496 - val_loss: 1.1355 - val_accuracy: 0.5750\n",
            "Epoch 63/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.0451 - accuracy: 0.6176 - val_loss: 1.1635 - val_accuracy: 0.5875\n",
            "Epoch 64/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.1859 - accuracy: 0.5510 - val_loss: 1.2919 - val_accuracy: 0.5250\n",
            "Epoch 65/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.1662 - accuracy: 0.5516 - val_loss: 1.1871 - val_accuracy: 0.6125\n",
            "Epoch 66/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 1.0248 - accuracy: 0.6262 - val_loss: 1.0754 - val_accuracy: 0.6250\n",
            "Epoch 67/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.0673 - accuracy: 0.6029 - val_loss: 1.1186 - val_accuracy: 0.5875\n",
            "Epoch 68/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 1.0047 - accuracy: 0.6123 - val_loss: 1.0811 - val_accuracy: 0.6250\n",
            "Epoch 69/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.9123 - accuracy: 0.6755 - val_loss: 1.1262 - val_accuracy: 0.6250\n",
            "Epoch 70/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.0276 - accuracy: 0.6209 - val_loss: 1.1472 - val_accuracy: 0.5875\n",
            "Epoch 71/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.9241 - accuracy: 0.6769 - val_loss: 1.0875 - val_accuracy: 0.5875\n",
            "Epoch 72/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.9373 - accuracy: 0.6656 - val_loss: 1.1483 - val_accuracy: 0.5750\n",
            "Epoch 73/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.9446 - accuracy: 0.6549 - val_loss: 1.0717 - val_accuracy: 0.6500\n",
            "Epoch 74/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.8950 - accuracy: 0.6542 - val_loss: 1.0483 - val_accuracy: 0.6250\n",
            "Epoch 75/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.8835 - accuracy: 0.6802 - val_loss: 1.0420 - val_accuracy: 0.6625\n",
            "Epoch 76/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.8605 - accuracy: 0.6755 - val_loss: 1.0942 - val_accuracy: 0.6250\n",
            "Epoch 77/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.8814 - accuracy: 0.6769 - val_loss: 1.0732 - val_accuracy: 0.6000\n",
            "Epoch 78/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.8150 - accuracy: 0.7089 - val_loss: 1.0565 - val_accuracy: 0.6625\n",
            "Epoch 79/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.8153 - accuracy: 0.7002 - val_loss: 1.0231 - val_accuracy: 0.6625\n",
            "Epoch 80/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.8304 - accuracy: 0.6989 - val_loss: 1.0923 - val_accuracy: 0.6250\n",
            "Epoch 81/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.9065 - accuracy: 0.6662 - val_loss: 1.0907 - val_accuracy: 0.5625\n",
            "Epoch 82/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.8516 - accuracy: 0.6895 - val_loss: 0.9954 - val_accuracy: 0.6500\n",
            "Epoch 83/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.8147 - accuracy: 0.7069 - val_loss: 1.0161 - val_accuracy: 0.6250\n",
            "Epoch 84/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.7859 - accuracy: 0.7089 - val_loss: 1.0155 - val_accuracy: 0.6375\n",
            "Epoch 85/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.7613 - accuracy: 0.7295 - val_loss: 1.0334 - val_accuracy: 0.6500\n",
            "Epoch 86/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.7672 - accuracy: 0.7215 - val_loss: 1.0340 - val_accuracy: 0.6625\n",
            "Epoch 87/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.7561 - accuracy: 0.7335 - val_loss: 0.9905 - val_accuracy: 0.6000\n",
            "Epoch 88/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.7506 - accuracy: 0.7268 - val_loss: 1.0026 - val_accuracy: 0.6000\n",
            "Epoch 89/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.7543 - accuracy: 0.7328 - val_loss: 1.0082 - val_accuracy: 0.6000\n",
            "Epoch 90/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.8566 - accuracy: 0.6909 - val_loss: 1.0350 - val_accuracy: 0.6375\n",
            "Epoch 91/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.8085 - accuracy: 0.7035 - val_loss: 1.0153 - val_accuracy: 0.6500\n",
            "Epoch 92/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.7978 - accuracy: 0.7129 - val_loss: 0.9926 - val_accuracy: 0.6500\n",
            "Epoch 93/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.9660 - accuracy: 0.6602 - val_loss: 1.1690 - val_accuracy: 0.5625\n",
            "Epoch 94/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.8458 - accuracy: 0.6929 - val_loss: 0.9916 - val_accuracy: 0.6500\n",
            "Epoch 95/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.7557 - accuracy: 0.7255 - val_loss: 0.9915 - val_accuracy: 0.6625\n",
            "Epoch 96/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.7420 - accuracy: 0.7255 - val_loss: 0.9843 - val_accuracy: 0.6875\n",
            "Epoch 97/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.7175 - accuracy: 0.7375 - val_loss: 0.9837 - val_accuracy: 0.6500\n",
            "Epoch 98/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.7088 - accuracy: 0.7355 - val_loss: 0.9685 - val_accuracy: 0.6500\n",
            "Epoch 99/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.6832 - accuracy: 0.7575 - val_loss: 0.9909 - val_accuracy: 0.6875\n",
            "Epoch 100/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.6818 - accuracy: 0.7555 - val_loss: 0.9714 - val_accuracy: 0.6750\n",
            "Epoch 101/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.7005 - accuracy: 0.7535 - val_loss: 1.0484 - val_accuracy: 0.6500\n",
            "Epoch 102/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.9425 - accuracy: 0.6622 - val_loss: 1.0961 - val_accuracy: 0.6250\n",
            "Epoch 103/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.7973 - accuracy: 0.7029 - val_loss: 1.0649 - val_accuracy: 0.5875\n",
            "Epoch 104/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.7811 - accuracy: 0.7029 - val_loss: 1.0263 - val_accuracy: 0.6125\n",
            "Epoch 105/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.7156 - accuracy: 0.7508 - val_loss: 0.9869 - val_accuracy: 0.6375\n",
            "Epoch 106/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.7583 - accuracy: 0.7175 - val_loss: 1.1542 - val_accuracy: 0.6375\n",
            "Epoch 107/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.0589 - accuracy: 0.6196 - val_loss: 1.1475 - val_accuracy: 0.5625\n",
            "Epoch 108/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.8152 - accuracy: 0.6969 - val_loss: 1.0301 - val_accuracy: 0.6000\n",
            "Epoch 109/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.7264 - accuracy: 0.7375 - val_loss: 1.0056 - val_accuracy: 0.6000\n",
            "Epoch 110/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.7035 - accuracy: 0.7388 - val_loss: 0.9500 - val_accuracy: 0.6250\n",
            "Epoch 111/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.7059 - accuracy: 0.7415 - val_loss: 0.9849 - val_accuracy: 0.6375\n",
            "Epoch 112/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.7548 - val_loss: 0.9506 - val_accuracy: 0.6625\n",
            "Epoch 113/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.6707 - accuracy: 0.7562 - val_loss: 0.9851 - val_accuracy: 0.6500\n",
            "Epoch 114/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.6919 - accuracy: 0.7488 - val_loss: 0.9690 - val_accuracy: 0.6375\n",
            "Epoch 115/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.6348 - accuracy: 0.7808 - val_loss: 0.9740 - val_accuracy: 0.6500\n",
            "Epoch 116/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.6430 - accuracy: 0.7755 - val_loss: 0.9977 - val_accuracy: 0.6625\n",
            "Epoch 117/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.6221 - accuracy: 0.7815 - val_loss: 1.0470 - val_accuracy: 0.7000\n",
            "Epoch 118/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.8060 - accuracy: 0.7149 - val_loss: 1.0796 - val_accuracy: 0.6250\n",
            "Epoch 119/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.7021 - accuracy: 0.7495 - val_loss: 0.9918 - val_accuracy: 0.6500\n",
            "Epoch 120/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.6739 - accuracy: 0.7595 - val_loss: 0.9975 - val_accuracy: 0.6250\n",
            "Epoch 121/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.6579 - accuracy: 0.7622 - val_loss: 0.9956 - val_accuracy: 0.6625\n",
            "Epoch 122/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.7245 - accuracy: 0.7308 - val_loss: 1.0098 - val_accuracy: 0.6625\n",
            "Epoch 123/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.7228 - accuracy: 0.7368 - val_loss: 0.9676 - val_accuracy: 0.6250\n",
            "Epoch 124/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.6907 - accuracy: 0.7402 - val_loss: 0.9737 - val_accuracy: 0.6250\n",
            "Epoch 125/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.6698 - accuracy: 0.7635 - val_loss: 1.0305 - val_accuracy: 0.5875\n",
            "Epoch 126/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.8071 - accuracy: 0.7015 - val_loss: 1.0591 - val_accuracy: 0.6625\n",
            "Epoch 127/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.7995 - accuracy: 0.7209 - val_loss: 0.9581 - val_accuracy: 0.6875\n",
            "Epoch 128/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.7180 - accuracy: 0.7442 - val_loss: 1.0287 - val_accuracy: 0.6750\n",
            "Epoch 129/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.7489 - accuracy: 0.7408 - val_loss: 0.9988 - val_accuracy: 0.6250\n",
            "Epoch 130/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.6783 - accuracy: 0.7628 - val_loss: 0.9795 - val_accuracy: 0.6625\n",
            "Epoch 131/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.6672 - accuracy: 0.7535 - val_loss: 1.0281 - val_accuracy: 0.6375\n",
            "Epoch 132/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.6339 - accuracy: 0.7708 - val_loss: 0.9721 - val_accuracy: 0.6125\n",
            "Epoch 133/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.6346 - accuracy: 0.7628 - val_loss: 1.0195 - val_accuracy: 0.6500\n",
            "Epoch 134/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5841 - accuracy: 0.7928 - val_loss: 0.9742 - val_accuracy: 0.6250\n",
            "Epoch 135/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.6064 - accuracy: 0.7868 - val_loss: 0.9654 - val_accuracy: 0.6125\n",
            "Epoch 136/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.6095 - accuracy: 0.7728 - val_loss: 1.0442 - val_accuracy: 0.6500\n",
            "Epoch 137/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.6915 - accuracy: 0.7542 - val_loss: 1.0639 - val_accuracy: 0.6250\n",
            "Epoch 138/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.6408 - accuracy: 0.7788 - val_loss: 1.0069 - val_accuracy: 0.6625\n",
            "Epoch 139/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.5821 - accuracy: 0.7975 - val_loss: 1.0371 - val_accuracy: 0.6500\n",
            "Epoch 140/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.6616 - accuracy: 0.7682 - val_loss: 1.1478 - val_accuracy: 0.5875\n",
            "Epoch 141/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 1.0696 - accuracy: 0.6682 - val_loss: 1.2392 - val_accuracy: 0.5500\n",
            "Epoch 142/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.8932 - accuracy: 0.6522 - val_loss: 1.0508 - val_accuracy: 0.6125\n",
            "Epoch 143/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.7126 - accuracy: 0.7308 - val_loss: 0.9492 - val_accuracy: 0.6375\n",
            "Epoch 144/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.6732 - accuracy: 0.7488 - val_loss: 0.9685 - val_accuracy: 0.6250\n",
            "Epoch 145/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.6602 - accuracy: 0.7495 - val_loss: 0.9793 - val_accuracy: 0.6250\n",
            "Epoch 146/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.6614 - accuracy: 0.7542 - val_loss: 0.9691 - val_accuracy: 0.6375\n",
            "Epoch 147/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.6147 - accuracy: 0.7715 - val_loss: 0.9517 - val_accuracy: 0.6500\n",
            "Epoch 148/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.6004 - accuracy: 0.7875 - val_loss: 0.9856 - val_accuracy: 0.6500\n",
            "Epoch 149/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5768 - accuracy: 0.7975 - val_loss: 0.9781 - val_accuracy: 0.6625\n",
            "Epoch 150/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5672 - accuracy: 0.7948 - val_loss: 0.9738 - val_accuracy: 0.6375\n",
            "Epoch 151/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5617 - accuracy: 0.7995 - val_loss: 1.0223 - val_accuracy: 0.6500\n",
            "Epoch 152/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.5945 - accuracy: 0.7855 - val_loss: 0.9721 - val_accuracy: 0.6500\n",
            "Epoch 153/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5530 - accuracy: 0.8068 - val_loss: 0.9638 - val_accuracy: 0.6750\n",
            "Epoch 154/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5358 - accuracy: 0.8101 - val_loss: 1.1029 - val_accuracy: 0.6500\n",
            "Epoch 155/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.7320 - accuracy: 0.7428 - val_loss: 1.1794 - val_accuracy: 0.5500\n",
            "Epoch 156/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.6248 - accuracy: 0.7715 - val_loss: 1.0251 - val_accuracy: 0.6500\n",
            "Epoch 157/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.6337 - accuracy: 0.7775 - val_loss: 1.0349 - val_accuracy: 0.6375\n",
            "Epoch 158/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.6220 - accuracy: 0.7788 - val_loss: 0.9902 - val_accuracy: 0.6625\n",
            "Epoch 159/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5672 - accuracy: 0.8055 - val_loss: 0.9769 - val_accuracy: 0.6750\n",
            "Epoch 160/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5547 - accuracy: 0.8068 - val_loss: 0.9682 - val_accuracy: 0.6750\n",
            "Epoch 161/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.6415 - accuracy: 0.7735 - val_loss: 0.9856 - val_accuracy: 0.6500\n",
            "Epoch 162/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.6091 - accuracy: 0.7788 - val_loss: 1.0115 - val_accuracy: 0.6750\n",
            "Epoch 163/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5549 - accuracy: 0.8081 - val_loss: 0.9675 - val_accuracy: 0.6875\n",
            "Epoch 164/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5215 - accuracy: 0.8248 - val_loss: 0.9886 - val_accuracy: 0.6500\n",
            "Epoch 165/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5526 - accuracy: 0.8208 - val_loss: 0.9829 - val_accuracy: 0.6500\n",
            "Epoch 166/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5423 - accuracy: 0.8041 - val_loss: 0.9926 - val_accuracy: 0.6625\n",
            "Epoch 167/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.5422 - accuracy: 0.7988 - val_loss: 1.0303 - val_accuracy: 0.6375\n",
            "Epoch 168/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5155 - accuracy: 0.8135 - val_loss: 0.9996 - val_accuracy: 0.6500\n",
            "Epoch 169/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.5206 - accuracy: 0.8115 - val_loss: 0.9769 - val_accuracy: 0.7000\n",
            "Epoch 170/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5680 - accuracy: 0.7995 - val_loss: 1.0025 - val_accuracy: 0.6750\n",
            "Epoch 171/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5716 - accuracy: 0.7935 - val_loss: 1.0114 - val_accuracy: 0.6625\n",
            "Epoch 172/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5368 - accuracy: 0.8015 - val_loss: 1.0019 - val_accuracy: 0.7000\n",
            "Epoch 173/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5154 - accuracy: 0.8175 - val_loss: 1.0359 - val_accuracy: 0.6375\n",
            "Epoch 174/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.4826 - accuracy: 0.8381 - val_loss: 1.0314 - val_accuracy: 0.6750\n",
            "Epoch 175/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4908 - accuracy: 0.8248 - val_loss: 1.0235 - val_accuracy: 0.6750\n",
            "Epoch 176/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4789 - accuracy: 0.8228 - val_loss: 1.0203 - val_accuracy: 0.6500\n",
            "Epoch 177/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4972 - accuracy: 0.8268 - val_loss: 1.0558 - val_accuracy: 0.6625\n",
            "Epoch 178/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.5106 - accuracy: 0.8175 - val_loss: 1.0582 - val_accuracy: 0.6375\n",
            "Epoch 179/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.6611 - accuracy: 0.7728 - val_loss: 1.0820 - val_accuracy: 0.6500\n",
            "Epoch 180/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5455 - accuracy: 0.8041 - val_loss: 1.0089 - val_accuracy: 0.6500\n",
            "Epoch 181/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.5376 - accuracy: 0.8095 - val_loss: 1.0492 - val_accuracy: 0.6500\n",
            "Epoch 182/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5258 - accuracy: 0.8161 - val_loss: 1.0396 - val_accuracy: 0.6250\n",
            "Epoch 183/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5440 - accuracy: 0.7988 - val_loss: 1.0183 - val_accuracy: 0.6625\n",
            "Epoch 184/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4726 - accuracy: 0.8308 - val_loss: 1.0640 - val_accuracy: 0.6250\n",
            "Epoch 185/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4840 - accuracy: 0.8235 - val_loss: 1.0819 - val_accuracy: 0.6250\n",
            "Epoch 186/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5206 - accuracy: 0.8168 - val_loss: 1.0793 - val_accuracy: 0.6375\n",
            "Epoch 187/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5074 - accuracy: 0.8188 - val_loss: 1.0610 - val_accuracy: 0.6500\n",
            "Epoch 188/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.4611 - accuracy: 0.8381 - val_loss: 1.0186 - val_accuracy: 0.6625\n",
            "Epoch 189/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4633 - accuracy: 0.8374 - val_loss: 1.0174 - val_accuracy: 0.6625\n",
            "Epoch 190/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.4593 - accuracy: 0.8368 - val_loss: 0.9818 - val_accuracy: 0.6625\n",
            "Epoch 191/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4310 - accuracy: 0.8441 - val_loss: 1.0255 - val_accuracy: 0.6625\n",
            "Epoch 192/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.4776 - accuracy: 0.8308 - val_loss: 1.0750 - val_accuracy: 0.6375\n",
            "Epoch 193/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4455 - accuracy: 0.8434 - val_loss: 1.0622 - val_accuracy: 0.6500\n",
            "Epoch 194/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4416 - accuracy: 0.8428 - val_loss: 1.0382 - val_accuracy: 0.6625\n",
            "Epoch 195/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4408 - accuracy: 0.8441 - val_loss: 1.0714 - val_accuracy: 0.6750\n",
            "Epoch 196/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.5656 - accuracy: 0.8028 - val_loss: 1.0550 - val_accuracy: 0.6875\n",
            "Epoch 197/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5037 - accuracy: 0.8208 - val_loss: 1.0636 - val_accuracy: 0.6375\n",
            "Epoch 198/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.4681 - accuracy: 0.8294 - val_loss: 1.0638 - val_accuracy: 0.6750\n",
            "Epoch 199/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5496 - accuracy: 0.8068 - val_loss: 1.1488 - val_accuracy: 0.6500\n",
            "Epoch 200/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.6028 - accuracy: 0.7868 - val_loss: 0.9999 - val_accuracy: 0.6500\n",
            "Epoch 201/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5527 - accuracy: 0.8035 - val_loss: 1.0089 - val_accuracy: 0.7125\n",
            "Epoch 202/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5078 - accuracy: 0.8115 - val_loss: 1.0717 - val_accuracy: 0.6750\n",
            "Epoch 203/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5084 - accuracy: 0.8135 - val_loss: 1.0219 - val_accuracy: 0.7125\n",
            "Epoch 204/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.4753 - accuracy: 0.8348 - val_loss: 1.0090 - val_accuracy: 0.6875\n",
            "Epoch 205/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4523 - accuracy: 0.8428 - val_loss: 1.0502 - val_accuracy: 0.6875\n",
            "Epoch 206/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4377 - accuracy: 0.8448 - val_loss: 1.0614 - val_accuracy: 0.6875\n",
            "Epoch 207/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4623 - accuracy: 0.8388 - val_loss: 1.0620 - val_accuracy: 0.6500\n",
            "Epoch 208/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4408 - accuracy: 0.8441 - val_loss: 1.0366 - val_accuracy: 0.6750\n",
            "Epoch 209/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4259 - accuracy: 0.8634 - val_loss: 1.0738 - val_accuracy: 0.6500\n",
            "Epoch 210/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4343 - accuracy: 0.8468 - val_loss: 1.0974 - val_accuracy: 0.6500\n",
            "Epoch 211/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4184 - accuracy: 0.8514 - val_loss: 1.0950 - val_accuracy: 0.6375\n",
            "Epoch 212/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4689 - accuracy: 0.8274 - val_loss: 1.1526 - val_accuracy: 0.6625\n",
            "Epoch 213/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4831 - accuracy: 0.8348 - val_loss: 1.1161 - val_accuracy: 0.6375\n",
            "Epoch 214/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4200 - accuracy: 0.8468 - val_loss: 1.0716 - val_accuracy: 0.6500\n",
            "Epoch 215/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4265 - accuracy: 0.8481 - val_loss: 1.0391 - val_accuracy: 0.6500\n",
            "Epoch 216/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4298 - accuracy: 0.8474 - val_loss: 1.0886 - val_accuracy: 0.6500\n",
            "Epoch 217/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4597 - accuracy: 0.8448 - val_loss: 1.1245 - val_accuracy: 0.6625\n",
            "Epoch 218/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4470 - accuracy: 0.8368 - val_loss: 0.9886 - val_accuracy: 0.7000\n",
            "Epoch 219/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4243 - accuracy: 0.8401 - val_loss: 1.0539 - val_accuracy: 0.6750\n",
            "Epoch 220/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3968 - accuracy: 0.8621 - val_loss: 1.0962 - val_accuracy: 0.6500\n",
            "Epoch 221/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5828 - accuracy: 0.7941 - val_loss: 1.1438 - val_accuracy: 0.6875\n",
            "Epoch 222/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5594 - accuracy: 0.7981 - val_loss: 1.0400 - val_accuracy: 0.7125\n",
            "Epoch 223/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4835 - accuracy: 0.8235 - val_loss: 1.0838 - val_accuracy: 0.6625\n",
            "Epoch 224/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.4383 - accuracy: 0.8454 - val_loss: 1.0591 - val_accuracy: 0.6750\n",
            "Epoch 225/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4284 - accuracy: 0.8554 - val_loss: 1.0425 - val_accuracy: 0.6750\n",
            "Epoch 226/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5292 - accuracy: 0.8215 - val_loss: 1.1101 - val_accuracy: 0.6750\n",
            "Epoch 227/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.5657 - accuracy: 0.8028 - val_loss: 1.1864 - val_accuracy: 0.6875\n",
            "Epoch 228/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4857 - accuracy: 0.8155 - val_loss: 1.1093 - val_accuracy: 0.6625\n",
            "Epoch 229/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4712 - accuracy: 0.8294 - val_loss: 1.0715 - val_accuracy: 0.6500\n",
            "Epoch 230/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4478 - accuracy: 0.8434 - val_loss: 1.1525 - val_accuracy: 0.6375\n",
            "Epoch 231/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4335 - accuracy: 0.8428 - val_loss: 1.0891 - val_accuracy: 0.6750\n",
            "Epoch 232/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5097 - accuracy: 0.8235 - val_loss: 0.9665 - val_accuracy: 0.7125\n",
            "Epoch 233/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4798 - accuracy: 0.8294 - val_loss: 1.0279 - val_accuracy: 0.6750\n",
            "Epoch 234/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.4335 - accuracy: 0.8361 - val_loss: 1.0325 - val_accuracy: 0.6750\n",
            "Epoch 235/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.4226 - accuracy: 0.8461 - val_loss: 1.0071 - val_accuracy: 0.6875\n",
            "Epoch 236/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3702 - accuracy: 0.8721 - val_loss: 1.0274 - val_accuracy: 0.6875\n",
            "Epoch 237/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4913 - accuracy: 0.8175 - val_loss: 1.2124 - val_accuracy: 0.6000\n",
            "Epoch 238/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.7817 - accuracy: 0.7368 - val_loss: 1.2077 - val_accuracy: 0.6250\n",
            "Epoch 239/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5109 - accuracy: 0.8188 - val_loss: 1.0585 - val_accuracy: 0.6500\n",
            "Epoch 240/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.4808 - accuracy: 0.8288 - val_loss: 1.0717 - val_accuracy: 0.6250\n",
            "Epoch 241/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.4483 - accuracy: 0.8428 - val_loss: 1.0661 - val_accuracy: 0.6500\n",
            "Epoch 242/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4129 - accuracy: 0.8574 - val_loss: 1.0406 - val_accuracy: 0.6875\n",
            "Epoch 243/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3738 - accuracy: 0.8714 - val_loss: 1.0375 - val_accuracy: 0.6625\n",
            "Epoch 244/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4097 - accuracy: 0.8574 - val_loss: 1.1193 - val_accuracy: 0.6625\n",
            "Epoch 245/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3966 - accuracy: 0.8701 - val_loss: 1.1306 - val_accuracy: 0.6625\n",
            "Epoch 246/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4134 - accuracy: 0.8554 - val_loss: 1.1482 - val_accuracy: 0.6750\n",
            "Epoch 247/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.4491 - accuracy: 0.8521 - val_loss: 1.0707 - val_accuracy: 0.6625\n",
            "Epoch 248/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3935 - accuracy: 0.8654 - val_loss: 1.2110 - val_accuracy: 0.6500\n",
            "Epoch 249/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.4383 - accuracy: 0.8528 - val_loss: 1.0956 - val_accuracy: 0.6625\n",
            "Epoch 250/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4372 - accuracy: 0.8454 - val_loss: 1.1482 - val_accuracy: 0.6500\n",
            "Epoch 251/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3925 - accuracy: 0.8674 - val_loss: 1.0633 - val_accuracy: 0.7000\n",
            "Epoch 252/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3732 - accuracy: 0.8701 - val_loss: 1.1028 - val_accuracy: 0.6875\n",
            "Epoch 253/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3674 - accuracy: 0.8748 - val_loss: 1.0669 - val_accuracy: 0.6625\n",
            "Epoch 254/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4919 - accuracy: 0.8208 - val_loss: 1.0959 - val_accuracy: 0.6625\n",
            "Epoch 255/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4401 - accuracy: 0.8441 - val_loss: 1.0656 - val_accuracy: 0.6625\n",
            "Epoch 256/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4152 - accuracy: 0.8421 - val_loss: 0.9735 - val_accuracy: 0.6875\n",
            "Epoch 257/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3898 - accuracy: 0.8621 - val_loss: 1.0135 - val_accuracy: 0.6875\n",
            "Epoch 258/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3622 - accuracy: 0.8648 - val_loss: 1.0801 - val_accuracy: 0.6625\n",
            "Epoch 259/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3538 - accuracy: 0.8688 - val_loss: 1.0682 - val_accuracy: 0.7000\n",
            "Epoch 260/300\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3257 - accuracy: 0.8894 - val_loss: 1.0815 - val_accuracy: 0.6875\n",
            "Epoch 261/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3484 - accuracy: 0.8827 - val_loss: 1.0970 - val_accuracy: 0.6750\n",
            "Epoch 262/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3442 - accuracy: 0.8867 - val_loss: 1.1298 - val_accuracy: 0.6375\n",
            "Epoch 263/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.4949 - accuracy: 0.8274 - val_loss: 1.1022 - val_accuracy: 0.6250\n",
            "Epoch 264/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3885 - accuracy: 0.8701 - val_loss: 1.0430 - val_accuracy: 0.6875\n",
            "Epoch 265/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3627 - accuracy: 0.8688 - val_loss: 1.0709 - val_accuracy: 0.6750\n",
            "Epoch 266/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3423 - accuracy: 0.8761 - val_loss: 1.0844 - val_accuracy: 0.6375\n",
            "Epoch 267/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3453 - accuracy: 0.8787 - val_loss: 1.1015 - val_accuracy: 0.6875\n",
            "Epoch 268/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3083 - accuracy: 0.8861 - val_loss: 1.2258 - val_accuracy: 0.6625\n",
            "Epoch 269/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.6036 - accuracy: 0.8021 - val_loss: 1.1405 - val_accuracy: 0.6125\n",
            "Epoch 270/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.4612 - accuracy: 0.8401 - val_loss: 1.0373 - val_accuracy: 0.6750\n",
            "Epoch 271/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.4578 - accuracy: 0.8381 - val_loss: 1.0925 - val_accuracy: 0.6500\n",
            "Epoch 272/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4138 - accuracy: 0.8501 - val_loss: 1.0921 - val_accuracy: 0.6625\n",
            "Epoch 273/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3565 - accuracy: 0.8748 - val_loss: 1.0756 - val_accuracy: 0.6625\n",
            "Epoch 274/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3526 - accuracy: 0.8814 - val_loss: 1.2140 - val_accuracy: 0.6375\n",
            "Epoch 275/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.6244 - accuracy: 0.7828 - val_loss: 1.2592 - val_accuracy: 0.5625\n",
            "Epoch 276/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.6735 - accuracy: 0.7608 - val_loss: 1.1494 - val_accuracy: 0.6000\n",
            "Epoch 277/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.5562 - accuracy: 0.7961 - val_loss: 0.9974 - val_accuracy: 0.6375\n",
            "Epoch 278/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.4869 - accuracy: 0.8235 - val_loss: 0.9951 - val_accuracy: 0.6750\n",
            "Epoch 279/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.4170 - accuracy: 0.8488 - val_loss: 1.0439 - val_accuracy: 0.6500\n",
            "Epoch 280/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4451 - accuracy: 0.8441 - val_loss: 1.1257 - val_accuracy: 0.6500\n",
            "Epoch 281/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4298 - accuracy: 0.8494 - val_loss: 1.0758 - val_accuracy: 0.6875\n",
            "Epoch 282/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3892 - accuracy: 0.8688 - val_loss: 0.9952 - val_accuracy: 0.7000\n",
            "Epoch 283/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.4007 - accuracy: 0.8628 - val_loss: 1.1239 - val_accuracy: 0.6625\n",
            "Epoch 284/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3583 - accuracy: 0.8834 - val_loss: 1.0615 - val_accuracy: 0.6750\n",
            "Epoch 285/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3663 - accuracy: 0.8714 - val_loss: 1.0968 - val_accuracy: 0.6875\n",
            "Epoch 286/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3368 - accuracy: 0.8834 - val_loss: 1.0597 - val_accuracy: 0.7000\n",
            "Epoch 287/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3299 - accuracy: 0.8901 - val_loss: 1.0915 - val_accuracy: 0.6625\n",
            "Epoch 288/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3212 - accuracy: 0.8841 - val_loss: 1.0310 - val_accuracy: 0.7000\n",
            "Epoch 289/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3222 - accuracy: 0.8821 - val_loss: 1.0685 - val_accuracy: 0.6875\n",
            "Epoch 290/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3167 - accuracy: 0.8907 - val_loss: 1.0672 - val_accuracy: 0.6875\n",
            "Epoch 291/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3297 - accuracy: 0.8914 - val_loss: 1.1199 - val_accuracy: 0.6625\n",
            "Epoch 292/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3602 - accuracy: 0.8681 - val_loss: 1.1273 - val_accuracy: 0.6500\n",
            "Epoch 293/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3504 - accuracy: 0.8681 - val_loss: 1.0659 - val_accuracy: 0.6875\n",
            "Epoch 294/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3413 - accuracy: 0.8827 - val_loss: 1.1223 - val_accuracy: 0.6750\n",
            "Epoch 295/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3840 - accuracy: 0.8601 - val_loss: 1.0035 - val_accuracy: 0.6500\n",
            "Epoch 296/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3541 - accuracy: 0.8701 - val_loss: 1.0577 - val_accuracy: 0.6375\n",
            "Epoch 297/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3478 - accuracy: 0.8694 - val_loss: 1.0328 - val_accuracy: 0.6500\n",
            "Epoch 298/300\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3035 - accuracy: 0.8954 - val_loss: 1.1659 - val_accuracy: 0.6500\n",
            "Epoch 299/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3009 - accuracy: 0.8981 - val_loss: 1.1617 - val_accuracy: 0.6250\n",
            "Epoch 300/300\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2826 - accuracy: 0.9014 - val_loss: 1.1347 - val_accuracy: 0.6875\n",
            "CPU times: user 45.4 s, sys: 11.6 s, total: 57 s\n",
            "Wall time: 1min 1s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49f3LOOc5ESG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0549718-3f08-4c68-fcb3-69945debc08f"
      },
      "source": [
        "  # Save model and weights\n",
        "model_name = \"birds_classify_v3.h5\"\n",
        "model.save(model_name)\n",
        "print('Saved trained model at %s ' % model_name)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved trained model at birds_classify_v3.h5 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fFP95nE5EDd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfd725e7-5c6e-44c6-940a-9ac80a2578d8"
      },
      "source": [
        "# Evaluate the model\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 3ms/step - loss: 1.1347 - accuracy: 0.6875\n",
            "Test loss: 1.1347371339797974\n",
            "Test accuracy: 0.6875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0fMc4Sk5DXc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fb8ecd6-b678-497e-de5d-16661f82a9a0"
      },
      "source": [
        "# classification report\n",
        "predictions = model.predict(x_test, verbose=1)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 2ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPn1ehz2CJjm"
      },
      "source": [
        "y_true, y_pred = [],[]\n",
        "classes = encoder.classes_\n",
        "for idx, prediction in enumerate(predictions): \n",
        "    y_true.append(classes[np.argmax(y_test[idx])])\n",
        "    y_pred.append(classes[np.argmax(prediction)])"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UDEzlc9DePo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d355f79e-1feb-4092-b4ae-b6e0d88c1218"
      },
      "source": [
        "print(classification_report(y_pred, y_true))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                     precision    recall  f1-score   support\n",
            "\n",
            "       AmericanCrow       0.77      0.83      0.80        52\n",
            "            BlueJay       0.84      0.78      0.81        68\n",
            "   EasternWoodPewee       0.68      0.64      0.66        50\n",
            "NorthernWaterthrush       0.42      0.66      0.51        38\n",
            "           Ovenbird       0.68      0.57      0.62        63\n",
            "              Veery       0.79      0.65      0.71        46\n",
            "\n",
            "           accuracy                           0.69       317\n",
            "          macro avg       0.70      0.69      0.69       317\n",
            "       weighted avg       0.71      0.69      0.70       317\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N_z4FZ6DefG"
      },
      "source": [
        "# confusion matrix\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(11, 11))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title, fontsize=30)\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=90, fontsize=15)\n",
        "    plt.yticks(tick_marks, classes, fontsize=15)\n",
        "\n",
        "    fmt = '.2f'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label', fontsize=25)\n",
        "    plt.xlabel('Predicted label', fontsize=25)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOXtGvCfDerZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "7bbad876-6be7-4dd6-c9e1-404408341867"
      },
      "source": [
        "cnf_matrix = confusion_matrix(y_pred, y_true)\n",
        "cnf_matrix = cnf_matrix.astype(float) / cnf_matrix.sum(axis=1)[:, np.newaxis]\n",
        "plot_confusion_matrix(cnf_matrix, classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-9d985333c799>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcnf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcnf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnf_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcnf_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnf_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvGMUK71DekC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G89yONe_DeV2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4PXm4heDeKC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}